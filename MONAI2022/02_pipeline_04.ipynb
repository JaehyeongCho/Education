{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96ohkCyqZNaM"
   },
   "source": [
    "#  MONAI Bootcamp\n",
    "## End-To-End Workflow with MONAI part 4 ( data partition + Ignite Supervised Evaluator and Trainer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_lPbckSZsAG"
   },
   "source": [
    "# same baseline End-to-end Training with Ignite\n",
    "We've covered a lot of material and now it's time to apply the things that we've learned in an end-to-end example. First, we're going to use the basic PyTorch paradigm for training our model. We'll then look at how to train using the Ignite workflows to make things even easier!\n",
    "\n",
    "## baseline  End-to-End Training Workflow\n",
    "To help guide you through training your first model using MONAI, this guide will will cover five key phases:\n",
    "\n",
    " 1. Setting up our Dataset and exploring the data\n",
    " 2. Preparing datasets and transforms\n",
    " 3. Define your network and create our PyTorch training loop [replace with ignite]\n",
    " 4. Evaluate your model and understand the results\n",
    " \n",
    "Let's get started by importing our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qg9upTKtVga-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import monai\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.data import decollate_batch, partition_dataset_classes\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    ToTensor,\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    EnsureType\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check GPU Memory with `nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  5 02:59:40 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:07:00.0 Off |                   On |\n",
      "| N/A   30C    P0    60W / 400W |   7588MiB / 81920MiB |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0    4   0   0  |     13MiB / 19968MiB | 28      0 |  2   0    1    0    0 |\n",
      "|                  |      0MiB / 32767MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBZIJLrJZ1IQ"
   },
   "source": [
    "## 1. Setting up our Dataset and exploring the data\n",
    "#### Setup data directory\n",
    "\n",
    "We'll create a temporary directory for all the MONAI data we're going to be using called temp directory in `~/monai-lab/temp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOX-pVqQVo01",
    "outputId": "cc1d2154-c38c-459b-92c9-4b9263447b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "directory = \"temp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQQ26Fv9Z-xK"
   },
   "source": [
    "Download the MedNIST dataset\n",
    "The MedNIST dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions), [the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4), and the [NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
    "\n",
    "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic) under the Creative Commons CC BY-SA 4.0 license. If you use the MedNIST dataset, please acknowledge the source.\n",
    "\n",
    "We're going to download this dataset below and extract it into our temporary MONAI Data Directory.\n",
    "It will take about 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_yH3E2_VvX7",
    "outputId": "04200657-6aea-4747-ad99-efe377a0dce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 218 µs, sys: 142 µs, total: 360 µs\n",
      "Wall time: 244 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "resource = \"https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz?dl=1\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccI6haMfaYSF"
   },
   "source": [
    "### Set deterministic training for reproducibility\n",
    "\n",
    "[`set_determinism`](https://docs.monai.io/en/latest/utils.html?highlight=set_determinism#monai.utils.misc.set_determinism) will set the random seeds in both Numpy and PyTorch to ensure reproducibility. We'll see later that we need to go a little bit further to ensure reproducibility in a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EwYpFBImV1hJ"
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uKHIr0Jaj2s"
   },
   "source": [
    "#### Read the image filenames from the dataset folders\n",
    "\n",
    "When using a dataset, you want to understand the basics of the images, labels, and more. We'll start off by showing some of those basic statistics for MedNIST.\n",
    "\n",
    "We'll see that 6 different folders are representing 6 different categories: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT. We'll be using each of these categories as our label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4T6KV7lV1ng",
    "outputId": "933bcb83-46c1-472d-b5db-c0e786b816c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image count: 58954\n",
      "Image dimensions: 64 x 64\n",
      "Label names: ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n",
      "number of Labels: 6\n",
      "Label counts: [10000, 8954, 10000, 10000, 10000, 10000]\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "\n",
    "image_files = [\n",
    "    [\n",
    "        os.path.join(data_dir, class_names[i], x)\n",
    "        for x in os.listdir(os.path.join(data_dir, class_names[i]))\n",
    "    ]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "image_class = []\n",
    "\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "    \n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"number of Labels: {num_class}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx-WedqRWDbt"
   },
   "source": [
    "# 2. Preparing datasets and transforms\n",
    "### Prepare training, validation, and test data lists\n",
    "\n",
    "We want to split the data into 3 different sets, one for training, one for validation, and one for testing. We'll use a ratio of 80/10/10 for those sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baseline manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vppWmX-BV1uN",
    "outputId": "74075068-0c62-4b37-8371-3cd0b9d0fa27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training count: 46946, Validation count: 6022, Test count: 5986\n"
     ]
    }
   ],
   "source": [
    "val_frac = 0.1\n",
    "test_frac = 0.1\n",
    "train_x = list()\n",
    "train_y = list()\n",
    "val_x = list()\n",
    "val_y = list()\n",
    "test_x = list()\n",
    "test_y = list()\n",
    "\n",
    "for i in range(num_total):\n",
    "    rann = np.random.random()\n",
    "    if rann < val_frac:\n",
    "        val_x.append(image_files_list[i])\n",
    "        val_y.append(image_class[i])\n",
    "    elif rann < test_frac + val_frac:\n",
    "        test_x.append(image_files_list[i])\n",
    "        test_y.append(image_class[i])\n",
    "    else:\n",
    "        train_x.append(image_files_list[i])\n",
    "        train_y.append(image_class[i])\n",
    "\n",
    "print(f\"Training count: {len(train_x)}, Validation count: {len(val_x)}, Test count: {len(test_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### manual with floor math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47164 5895 5895\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "# make this selection deterministic and controllable by seed\n",
    "dataset_seed = 12345678\n",
    "r = np.random.RandomState(dataset_seed)\n",
    "\n",
    "# calculate the number of images we want for the validation and test groups\n",
    "validation_proportion = 0.1\n",
    "test_proportion = 0.1\n",
    "validation_count = floor(validation_proportion * num_total)\n",
    "test_count = floor(test_proportion * num_total)\n",
    "\n",
    "groups = np.zeros(num_total, dtype=np.int32)\n",
    "\n",
    "# set the appropriate number of '1's for the validation dataset\n",
    "groups[:validation_count] = 1\n",
    "\n",
    "# then set the appropriate number of '2's for the test dataset\n",
    "groups[validation_count:validation_count + test_count] = 2\n",
    "\n",
    "# Shuffle the sequence so that \n",
    "r.shuffle(groups)\n",
    "\n",
    "image_sets = list(), list(), list()\n",
    "label_sets = list(), list(), list()\n",
    "\n",
    "for n in range(num_total):\n",
    "    image_sets[groups[n]].append(image_files_list[n])\n",
    "    label_sets[groups[n]].append(image_class[n])\n",
    "    \n",
    "train_x, val_x, test_x = image_sets\n",
    "train_y, val_y, test_y = label_sets\n",
    "print(len(train_x), len(val_x), len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### partition with shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training count: 47163, Validation count: 5895, Test count: 5895\n"
     ]
    }
   ],
   "source": [
    "train_inds, val_inds, test_inds = partition_dataset_classes(np.arange(len(image_files_list)), \n",
    "                                                            image_class,(8, 1, 1), shuffle=True)\n",
    "\n",
    "train_x = [image_files_list[i] for i in train_inds]\n",
    "train_y = [image_class[i] for i in train_inds]\n",
    "val_x = [image_files_list[i] for i in val_inds]\n",
    "val_y = [image_class[i] for i in val_inds]\n",
    "test_x = [image_files_list[i] for i in test_inds]\n",
    "test_y = [image_class[i] for i in test_inds]\n",
    "\n",
    "print(f\"Training count: {len(train_x)}, Validation count: {len(val_x)}, Test count: {len(test_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### partition with suffle and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47163 5895 5895\n"
     ]
    }
   ],
   "source": [
    "rseed = 12345678\n",
    "parts = partition_dataset_classes(\n",
    "    data=np.arange(len(image_files_list)), \n",
    "    classes=image_class, \n",
    "    ratios=(8, 1, 1), \n",
    "    shuffle=True, \n",
    "    seed=rseed\n",
    ")\n",
    "\n",
    "image_sets = [list(), list(), list()]\n",
    "label_sets = [list(), list(), list()]\n",
    "\n",
    "for i, part in enumerate(parts):\n",
    "    image_sets[i] = [image_files_list[idx] for idx in part]\n",
    "    label_sets[i] = [image_class[idx] for idx in part]\n",
    "\n",
    "train_x, val_x, test_x = image_sets\n",
    "train_y, val_y, test_y = label_sets\n",
    "print(len(train_x), len(val_x), len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQKPHOjgWHoW"
   },
   "source": [
    "### Define MONAI transforms, Dataset and Dataloader to pre-process data\n",
    "\n",
    "We'll define our transform using `Compose`. In this Array of Transforms, we'll load the image, add a channel, scale its intensity, utilize a few random functions and finally create a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaRvhLd-WTmF",
    "outputId": "619dac29-2ec4-4bb3-bf52-9bf49780c17e"
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadImage(image_only=True), AddChannel(), ScaleIntensity(), ToTensor()])\n",
    "\n",
    "act = Compose([EnsureType(), Activations(softmax=True)])\n",
    "to_onehot = Compose([EnsureType(), AsDiscrete(to_onehot=num_class, n_classes=num_class)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DeElxN0WcKt"
   },
   "source": [
    "### Initialise the datasets and loaders for training, validation and test sets\n",
    "- Define a simple dataset, that we'll call `MedNISTDataset`, that  groups:\n",
    "\n",
    " - Images\n",
    " - Labels\n",
    " - The transforms that are to be run on the images and labels\n",
    "- Create three instances of this dataset:\n",
    "  - One for training\n",
    "  - One for validation\n",
    "  - One for testing\n",
    "\n",
    "We'll use a batch size of 512 and employ 10 workers to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fag4Yd2CWTum",
    "outputId": "af0aca02-0916-4909-9da7-8a14f57c1a20"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_workers = 4\n",
    "\n",
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Df90U_QrW0i6"
   },
   "source": [
    "3. Define your network and create our PyTorch training loop\n",
    "Define network and optimizer\n",
    "Set learning_rate for how much the model is updated per step\n",
    "The fetch a pytorch device for the GPU\n",
    "Instantiate a `densenet121` model instance and 'send' it to the GPU using device\n",
    "This is a standard MONAI implementation; it is capable of 2D and 3D operation but here we are using it in 2D mode\n",
    "We'll make use of the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B0Fxk7CNWTxg"
   },
   "outputs": [],
   "source": [
    "# Configure \n",
    "learning_rate = 1e-5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyIfXHW9W3rW"
   },
   "source": [
    "\n",
    "## Let's use ignite (Supervised Evaluator and trainer)\n",
    "Everything that we have done so far uses MONAI with pytorch in a very vanilla fashion. The initial training / validation loop is written to show you the nuts and bolts of pytorch. Now let's explore starting the move towards Ignite and features of MONAI designed to work with it.\n",
    "\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/workflows.png\" width=600>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize network, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure \n",
    "learning_rate = 1e-5\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load ignite module and initialize  buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.metrics import Accuracy\n",
    "from monai.handlers import ROCAUC, ValidationHandler\n",
    "from monai.engines import SupervisedTrainer, SupervisedEvaluator\n",
    "step = 1\n",
    "train_epochs = 4\n",
    "iter_losses = []\n",
    "batch_sizes = []\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### configure roc metric (same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "steps_per_epoch = len(train_ds) // train_loader.batch_size\n",
    "if len(train_ds) % train_loader.batch_size != 0:\n",
    "    steps_per_epoch += 1\n",
    "\n",
    "\n",
    "def roc_auc_trans(x):\n",
    "    if isinstance(x, list):\n",
    "        pred = torch.cat([i[0][None, :] for i in x])\n",
    "        label = torch.cat([i[1][None, :] for i in x])\n",
    "        return pred, label\n",
    "\n",
    "    return act(x[\"pred\"]), to_onehot(x[\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### configure ignite Supervised Evaluator and trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_batch(batchdata, device, non_blocking):\n",
    "    img, classes = batchdata\n",
    "    return img.to(device), classes.to(device)\n",
    "\n",
    "\n",
    "evaluator = SupervisedEvaluator(\n",
    "    device=device,\n",
    "    val_data_loader=val_loader,\n",
    "    network=net,\n",
    "    postprocessing=roc_auc_trans,\n",
    "    key_val_metric={\"rocauc\": ROCAUC(output_transform=roc_auc_trans)},\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n",
    "\n",
    "trainer = SupervisedTrainer(\n",
    "    device=device,\n",
    "    max_epochs=train_epochs,\n",
    "    train_data_loader=train_loader,\n",
    "    network=net,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    train_handlers=[ValidationHandler(1, evaluator)],\n",
    "    prepare_batch=prepare_batch,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### configure event handler for iteration and epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "IBDD_Iq0Yh5j"
   },
   "outputs": [],
   "source": [
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def _end_iter(engine):\n",
    "    global step\n",
    "    loss = np.average([o[\"loss\"] for o in engine.state.output])\n",
    "    batch_len = len(engine.state.batch[0])\n",
    "    epoch = engine.state.epoch\n",
    "    epoch_len = engine.state.max_epochs\n",
    "    step_total = engine.state.iteration  \n",
    "    iter_losses.append(loss)\n",
    "    batch_sizes.append(batch_len)\n",
    "\n",
    "    print(f\"epoch {epoch}/{epoch_len}, step {step}/{steps_per_epoch}, total step {step_total}/{steps_per_epoch*epoch_len}, training_loss = {loss:.4f}\")\n",
    "    step += 1\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def run_validation(engine):\n",
    "    global step\n",
    "    # the overall average loss must be weighted by batch size\n",
    "    overall_average_loss = np.average(iter_losses, weights=batch_sizes)\n",
    "    epoch_loss_values.append(overall_average_loss)\n",
    "\n",
    "    # clear the contents of iter_losses and batch_sizes for the next epoch\n",
    "    del iter_losses[:]\n",
    "    del batch_sizes[:]\n",
    "\n",
    "    # fetch and report the validation metrics\n",
    "    roc = evaluator.state.metrics[\"rocauc\"]\n",
    "    metric_values.append(roc)\n",
    "    print(f\"evaluation for epoch {engine.state.epoch},  rocauc = {roc:.4f}\")\n",
    "    step = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### launch ignite trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTtDjwG3YkJZ",
    "outputId": "ce99b12f-234f-459e-f7db-4ad30d3b86f6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/4, step 1/93, total step 1/372, training_loss = 1.8325\n",
      "epoch 1/4, step 2/93, total step 2/372, training_loss = 1.7940\n",
      "epoch 1/4, step 3/93, total step 3/372, training_loss = 1.7789\n",
      "epoch 1/4, step 4/93, total step 4/372, training_loss = 1.7886\n",
      "epoch 1/4, step 5/93, total step 5/372, training_loss = 1.7380\n",
      "epoch 1/4, step 6/93, total step 6/372, training_loss = 1.7141\n",
      "epoch 1/4, step 7/93, total step 7/372, training_loss = 1.6948\n",
      "epoch 1/4, step 8/93, total step 8/372, training_loss = 1.6628\n",
      "epoch 1/4, step 9/93, total step 9/372, training_loss = 1.6326\n",
      "epoch 1/4, step 10/93, total step 10/372, training_loss = 1.6031\n",
      "epoch 1/4, step 11/93, total step 11/372, training_loss = 1.6029\n",
      "epoch 1/4, step 12/93, total step 12/372, training_loss = 1.5629\n",
      "epoch 1/4, step 13/93, total step 13/372, training_loss = 1.5506\n",
      "epoch 1/4, step 14/93, total step 14/372, training_loss = 1.5302\n",
      "epoch 1/4, step 15/93, total step 15/372, training_loss = 1.4928\n",
      "epoch 1/4, step 16/93, total step 16/372, training_loss = 1.4512\n",
      "epoch 1/4, step 17/93, total step 17/372, training_loss = 1.4750\n",
      "epoch 1/4, step 18/93, total step 18/372, training_loss = 1.4127\n",
      "epoch 1/4, step 19/93, total step 19/372, training_loss = 1.4013\n",
      "epoch 1/4, step 20/93, total step 20/372, training_loss = 1.4018\n",
      "epoch 1/4, step 21/93, total step 21/372, training_loss = 1.3693\n",
      "epoch 1/4, step 22/93, total step 22/372, training_loss = 1.3636\n",
      "epoch 1/4, step 23/93, total step 23/372, training_loss = 1.3594\n",
      "epoch 1/4, step 24/93, total step 24/372, training_loss = 1.3316\n",
      "epoch 1/4, step 25/93, total step 25/372, training_loss = 1.3036\n",
      "epoch 1/4, step 26/93, total step 26/372, training_loss = 1.2837\n",
      "epoch 1/4, step 27/93, total step 27/372, training_loss = 1.2645\n",
      "epoch 1/4, step 28/93, total step 28/372, training_loss = 1.2726\n",
      "epoch 1/4, step 29/93, total step 29/372, training_loss = 1.2447\n",
      "epoch 1/4, step 30/93, total step 30/372, training_loss = 1.2268\n",
      "epoch 1/4, step 31/93, total step 31/372, training_loss = 1.2216\n",
      "epoch 1/4, step 32/93, total step 32/372, training_loss = 1.2049\n",
      "epoch 1/4, step 33/93, total step 33/372, training_loss = 1.1825\n",
      "epoch 1/4, step 34/93, total step 34/372, training_loss = 1.1758\n",
      "epoch 1/4, step 35/93, total step 35/372, training_loss = 1.1377\n",
      "epoch 1/4, step 36/93, total step 36/372, training_loss = 1.1497\n",
      "epoch 1/4, step 37/93, total step 37/372, training_loss = 1.1160\n",
      "epoch 1/4, step 38/93, total step 38/372, training_loss = 1.1012\n",
      "epoch 1/4, step 39/93, total step 39/372, training_loss = 1.0783\n",
      "epoch 1/4, step 40/93, total step 40/372, training_loss = 1.0931\n",
      "epoch 1/4, step 41/93, total step 41/372, training_loss = 1.0602\n",
      "epoch 1/4, step 42/93, total step 42/372, training_loss = 1.0642\n",
      "epoch 1/4, step 43/93, total step 43/372, training_loss = 1.0369\n",
      "epoch 1/4, step 44/93, total step 44/372, training_loss = 1.0110\n",
      "epoch 1/4, step 45/93, total step 45/372, training_loss = 1.0023\n",
      "epoch 1/4, step 46/93, total step 46/372, training_loss = 0.9668\n",
      "epoch 1/4, step 47/93, total step 47/372, training_loss = 1.0188\n",
      "epoch 1/4, step 48/93, total step 48/372, training_loss = 0.9552\n",
      "epoch 1/4, step 49/93, total step 49/372, training_loss = 0.9527\n",
      "epoch 1/4, step 50/93, total step 50/372, training_loss = 0.9573\n",
      "epoch 1/4, step 51/93, total step 51/372, training_loss = 0.9328\n",
      "epoch 1/4, step 52/93, total step 52/372, training_loss = 0.8826\n",
      "epoch 1/4, step 53/93, total step 53/372, training_loss = 0.8859\n",
      "epoch 1/4, step 54/93, total step 54/372, training_loss = 0.8703\n",
      "epoch 1/4, step 55/93, total step 55/372, training_loss = 0.8496\n",
      "epoch 1/4, step 56/93, total step 56/372, training_loss = 0.8548\n",
      "epoch 1/4, step 57/93, total step 57/372, training_loss = 0.8775\n",
      "epoch 1/4, step 58/93, total step 58/372, training_loss = 0.8319\n",
      "epoch 1/4, step 59/93, total step 59/372, training_loss = 0.8291\n",
      "epoch 1/4, step 60/93, total step 60/372, training_loss = 0.8333\n",
      "epoch 1/4, step 61/93, total step 61/372, training_loss = 0.8148\n",
      "epoch 1/4, step 62/93, total step 62/372, training_loss = 0.7974\n",
      "epoch 1/4, step 63/93, total step 63/372, training_loss = 0.8019\n",
      "epoch 1/4, step 64/93, total step 64/372, training_loss = 0.7895\n",
      "epoch 1/4, step 65/93, total step 65/372, training_loss = 0.7389\n",
      "epoch 1/4, step 66/93, total step 66/372, training_loss = 0.7554\n",
      "epoch 1/4, step 67/93, total step 67/372, training_loss = 0.7173\n",
      "epoch 1/4, step 68/93, total step 68/372, training_loss = 0.7116\n",
      "epoch 1/4, step 69/93, total step 69/372, training_loss = 0.7289\n",
      "epoch 1/4, step 70/93, total step 70/372, training_loss = 0.7064\n",
      "epoch 1/4, step 71/93, total step 71/372, training_loss = 0.6802\n",
      "epoch 1/4, step 72/93, total step 72/372, training_loss = 0.7473\n",
      "epoch 1/4, step 73/93, total step 73/372, training_loss = 0.6936\n",
      "epoch 1/4, step 74/93, total step 74/372, training_loss = 0.6819\n",
      "epoch 1/4, step 75/93, total step 75/372, training_loss = 0.6822\n",
      "epoch 1/4, step 76/93, total step 76/372, training_loss = 0.6420\n",
      "epoch 1/4, step 77/93, total step 77/372, training_loss = 0.6710\n",
      "epoch 1/4, step 78/93, total step 78/372, training_loss = 0.6488\n",
      "epoch 1/4, step 79/93, total step 79/372, training_loss = 0.6602\n",
      "epoch 1/4, step 80/93, total step 80/372, training_loss = 0.6286\n",
      "epoch 1/4, step 81/93, total step 81/372, training_loss = 0.6504\n",
      "epoch 1/4, step 82/93, total step 82/372, training_loss = 0.6483\n",
      "epoch 1/4, step 83/93, total step 83/372, training_loss = 0.6077\n",
      "epoch 1/4, step 84/93, total step 84/372, training_loss = 0.6388\n",
      "epoch 1/4, step 85/93, total step 85/372, training_loss = 0.5959\n",
      "epoch 1/4, step 86/93, total step 86/372, training_loss = 0.5937\n",
      "epoch 1/4, step 87/93, total step 87/372, training_loss = 0.6121\n",
      "epoch 1/4, step 88/93, total step 88/372, training_loss = 0.5390\n",
      "epoch 1/4, step 89/93, total step 89/372, training_loss = 0.5457\n",
      "epoch 1/4, step 90/93, total step 90/372, training_loss = 0.5603\n",
      "epoch 1/4, step 91/93, total step 91/372, training_loss = 0.5916\n",
      "epoch 1/4, step 92/93, total step 92/372, training_loss = 0.5242\n",
      "epoch 1/4, step 93/93, total step 93/372, training_loss = 0.4863\n",
      "evaluation for epoch 1,  rocauc = 0.9935\n",
      "epoch 2/4, step 1/93, total step 94/372, training_loss = 0.5646\n",
      "epoch 2/4, step 2/93, total step 95/372, training_loss = 0.5348\n",
      "epoch 2/4, step 3/93, total step 96/372, training_loss = 0.5400\n",
      "epoch 2/4, step 4/93, total step 97/372, training_loss = 0.5089\n",
      "epoch 2/4, step 5/93, total step 98/372, training_loss = 0.5180\n",
      "epoch 2/4, step 6/93, total step 99/372, training_loss = 0.5231\n",
      "epoch 2/4, step 7/93, total step 100/372, training_loss = 0.5097\n",
      "epoch 2/4, step 8/93, total step 101/372, training_loss = 0.4701\n",
      "epoch 2/4, step 9/93, total step 102/372, training_loss = 0.4840\n",
      "epoch 2/4, step 10/93, total step 103/372, training_loss = 0.5038\n",
      "epoch 2/4, step 11/93, total step 104/372, training_loss = 0.4911\n",
      "epoch 2/4, step 12/93, total step 105/372, training_loss = 0.4971\n",
      "epoch 2/4, step 13/93, total step 106/372, training_loss = 0.4432\n",
      "epoch 2/4, step 14/93, total step 107/372, training_loss = 0.4910\n",
      "epoch 2/4, step 15/93, total step 108/372, training_loss = 0.4415\n",
      "epoch 2/4, step 16/93, total step 109/372, training_loss = 0.4492\n",
      "epoch 2/4, step 17/93, total step 110/372, training_loss = 0.4597\n",
      "epoch 2/4, step 18/93, total step 111/372, training_loss = 0.4491\n",
      "epoch 2/4, step 19/93, total step 112/372, training_loss = 0.4520\n",
      "epoch 2/4, step 20/93, total step 113/372, training_loss = 0.4600\n",
      "epoch 2/4, step 21/93, total step 114/372, training_loss = 0.4316\n",
      "epoch 2/4, step 22/93, total step 115/372, training_loss = 0.4594\n",
      "epoch 2/4, step 23/93, total step 116/372, training_loss = 0.4481\n",
      "epoch 2/4, step 24/93, total step 117/372, training_loss = 0.4080\n",
      "epoch 2/4, step 25/93, total step 118/372, training_loss = 0.4039\n",
      "epoch 2/4, step 26/93, total step 119/372, training_loss = 0.3976\n",
      "epoch 2/4, step 27/93, total step 120/372, training_loss = 0.4124\n",
      "epoch 2/4, step 28/93, total step 121/372, training_loss = 0.4448\n",
      "epoch 2/4, step 29/93, total step 122/372, training_loss = 0.4116\n",
      "epoch 2/4, step 30/93, total step 123/372, training_loss = 0.3656\n",
      "epoch 2/4, step 31/93, total step 124/372, training_loss = 0.3949\n",
      "epoch 2/4, step 32/93, total step 125/372, training_loss = 0.3999\n",
      "epoch 2/4, step 33/93, total step 126/372, training_loss = 0.3703\n",
      "epoch 2/4, step 34/93, total step 127/372, training_loss = 0.3880\n",
      "epoch 2/4, step 35/93, total step 128/372, training_loss = 0.3885\n",
      "epoch 2/4, step 36/93, total step 129/372, training_loss = 0.3865\n",
      "epoch 2/4, step 37/93, total step 130/372, training_loss = 0.3568\n",
      "epoch 2/4, step 38/93, total step 131/372, training_loss = 0.3863\n",
      "epoch 2/4, step 39/93, total step 132/372, training_loss = 0.3676\n",
      "epoch 2/4, step 40/93, total step 133/372, training_loss = 0.3173\n",
      "epoch 2/4, step 41/93, total step 134/372, training_loss = 0.3560\n",
      "epoch 2/4, step 42/93, total step 135/372, training_loss = 0.3494\n",
      "epoch 2/4, step 43/93, total step 136/372, training_loss = 0.3487\n",
      "epoch 2/4, step 44/93, total step 137/372, training_loss = 0.3403\n",
      "epoch 2/4, step 45/93, total step 138/372, training_loss = 0.3778\n",
      "epoch 2/4, step 46/93, total step 139/372, training_loss = 0.3666\n",
      "epoch 2/4, step 47/93, total step 140/372, training_loss = 0.3602\n",
      "epoch 2/4, step 48/93, total step 141/372, training_loss = 0.3605\n",
      "epoch 2/4, step 49/93, total step 142/372, training_loss = 0.3237\n",
      "epoch 2/4, step 50/93, total step 143/372, training_loss = 0.3283\n",
      "epoch 2/4, step 51/93, total step 144/372, training_loss = 0.3215\n",
      "epoch 2/4, step 52/93, total step 145/372, training_loss = 0.3198\n",
      "epoch 2/4, step 53/93, total step 146/372, training_loss = 0.3086\n",
      "epoch 2/4, step 54/93, total step 147/372, training_loss = 0.3146\n",
      "epoch 2/4, step 55/93, total step 148/372, training_loss = 0.3064\n",
      "epoch 2/4, step 56/93, total step 149/372, training_loss = 0.2935\n",
      "epoch 2/4, step 57/93, total step 150/372, training_loss = 0.3418\n",
      "epoch 2/4, step 58/93, total step 151/372, training_loss = 0.3282\n",
      "epoch 2/4, step 59/93, total step 152/372, training_loss = 0.2952\n",
      "epoch 2/4, step 60/93, total step 153/372, training_loss = 0.3008\n",
      "epoch 2/4, step 61/93, total step 154/372, training_loss = 0.3161\n",
      "epoch 2/4, step 62/93, total step 155/372, training_loss = 0.3030\n",
      "epoch 2/4, step 63/93, total step 156/372, training_loss = 0.2755\n",
      "epoch 2/4, step 64/93, total step 157/372, training_loss = 0.2915\n",
      "epoch 2/4, step 65/93, total step 158/372, training_loss = 0.2906\n",
      "epoch 2/4, step 66/93, total step 159/372, training_loss = 0.2801\n",
      "epoch 2/4, step 67/93, total step 160/372, training_loss = 0.3071\n",
      "epoch 2/4, step 68/93, total step 161/372, training_loss = 0.2796\n",
      "epoch 2/4, step 69/93, total step 162/372, training_loss = 0.2865\n",
      "epoch 2/4, step 70/93, total step 163/372, training_loss = 0.2762\n",
      "epoch 2/4, step 71/93, total step 164/372, training_loss = 0.3135\n",
      "epoch 2/4, step 72/93, total step 165/372, training_loss = 0.3042\n",
      "epoch 2/4, step 73/93, total step 166/372, training_loss = 0.2608\n",
      "epoch 2/4, step 74/93, total step 167/372, training_loss = 0.2602\n",
      "epoch 2/4, step 75/93, total step 168/372, training_loss = 0.2381\n",
      "epoch 2/4, step 76/93, total step 169/372, training_loss = 0.2675\n",
      "epoch 2/4, step 77/93, total step 170/372, training_loss = 0.2722\n",
      "epoch 2/4, step 78/93, total step 171/372, training_loss = 0.2497\n",
      "epoch 2/4, step 79/93, total step 172/372, training_loss = 0.2450\n",
      "epoch 2/4, step 80/93, total step 173/372, training_loss = 0.2356\n",
      "epoch 2/4, step 81/93, total step 174/372, training_loss = 0.2650\n",
      "epoch 2/4, step 82/93, total step 175/372, training_loss = 0.2596\n",
      "epoch 2/4, step 83/93, total step 176/372, training_loss = 0.2597\n",
      "epoch 2/4, step 84/93, total step 177/372, training_loss = 0.2386\n",
      "epoch 2/4, step 85/93, total step 178/372, training_loss = 0.2261\n",
      "epoch 2/4, step 86/93, total step 179/372, training_loss = 0.2213\n",
      "epoch 2/4, step 87/93, total step 180/372, training_loss = 0.2394\n",
      "epoch 2/4, step 88/93, total step 181/372, training_loss = 0.2465\n",
      "epoch 2/4, step 89/93, total step 182/372, training_loss = 0.2678\n",
      "epoch 2/4, step 90/93, total step 183/372, training_loss = 0.2599\n",
      "epoch 2/4, step 91/93, total step 184/372, training_loss = 0.2395\n",
      "epoch 2/4, step 92/93, total step 185/372, training_loss = 0.2645\n",
      "epoch 2/4, step 93/93, total step 186/372, training_loss = 0.4296\n",
      "evaluation for epoch 2,  rocauc = 0.9981\n",
      "epoch 3/4, step 1/93, total step 187/372, training_loss = 0.2291\n",
      "epoch 3/4, step 2/93, total step 188/372, training_loss = 0.2317\n",
      "epoch 3/4, step 3/93, total step 189/372, training_loss = 0.2281\n",
      "epoch 3/4, step 4/93, total step 190/372, training_loss = 0.2183\n",
      "epoch 3/4, step 5/93, total step 191/372, training_loss = 0.2432\n",
      "epoch 3/4, step 6/93, total step 192/372, training_loss = 0.2225\n",
      "epoch 3/4, step 7/93, total step 193/372, training_loss = 0.2272\n",
      "epoch 3/4, step 8/93, total step 194/372, training_loss = 0.2401\n",
      "epoch 3/4, step 9/93, total step 195/372, training_loss = 0.2200\n",
      "epoch 3/4, step 10/93, total step 196/372, training_loss = 0.2121\n",
      "epoch 3/4, step 11/93, total step 197/372, training_loss = 0.2154\n",
      "epoch 3/4, step 12/93, total step 198/372, training_loss = 0.2098\n",
      "epoch 3/4, step 13/93, total step 199/372, training_loss = 0.2298\n",
      "epoch 3/4, step 14/93, total step 200/372, training_loss = 0.2024\n",
      "epoch 3/4, step 15/93, total step 201/372, training_loss = 0.1991\n",
      "epoch 3/4, step 16/93, total step 202/372, training_loss = 0.1722\n",
      "epoch 3/4, step 17/93, total step 203/372, training_loss = 0.2118\n",
      "epoch 3/4, step 18/93, total step 204/372, training_loss = 0.2377\n",
      "epoch 3/4, step 19/93, total step 205/372, training_loss = 0.2139\n",
      "epoch 3/4, step 20/93, total step 206/372, training_loss = 0.2330\n",
      "epoch 3/4, step 21/93, total step 207/372, training_loss = 0.1980\n",
      "epoch 3/4, step 22/93, total step 208/372, training_loss = 0.2124\n",
      "epoch 3/4, step 23/93, total step 209/372, training_loss = 0.2056\n",
      "epoch 3/4, step 24/93, total step 210/372, training_loss = 0.1930\n",
      "epoch 3/4, step 25/93, total step 211/372, training_loss = 0.1839\n",
      "epoch 3/4, step 26/93, total step 212/372, training_loss = 0.2228\n",
      "epoch 3/4, step 27/93, total step 213/372, training_loss = 0.2127\n",
      "epoch 3/4, step 28/93, total step 214/372, training_loss = 0.2064\n",
      "epoch 3/4, step 29/93, total step 215/372, training_loss = 0.2024\n",
      "epoch 3/4, step 30/93, total step 216/372, training_loss = 0.1975\n",
      "epoch 3/4, step 31/93, total step 217/372, training_loss = 0.2088\n",
      "epoch 3/4, step 32/93, total step 218/372, training_loss = 0.2010\n",
      "epoch 3/4, step 33/93, total step 219/372, training_loss = 0.1957\n",
      "epoch 3/4, step 34/93, total step 220/372, training_loss = 0.1862\n",
      "epoch 3/4, step 35/93, total step 221/372, training_loss = 0.2412\n",
      "epoch 3/4, step 36/93, total step 222/372, training_loss = 0.2083\n",
      "epoch 3/4, step 37/93, total step 223/372, training_loss = 0.2030\n",
      "epoch 3/4, step 38/93, total step 224/372, training_loss = 0.1622\n",
      "epoch 3/4, step 39/93, total step 225/372, training_loss = 0.1814\n",
      "epoch 3/4, step 40/93, total step 226/372, training_loss = 0.1850\n",
      "epoch 3/4, step 41/93, total step 227/372, training_loss = 0.2040\n",
      "epoch 3/4, step 42/93, total step 228/372, training_loss = 0.1672\n",
      "epoch 3/4, step 43/93, total step 229/372, training_loss = 0.1688\n",
      "epoch 3/4, step 44/93, total step 230/372, training_loss = 0.1698\n",
      "epoch 3/4, step 45/93, total step 231/372, training_loss = 0.1759\n",
      "epoch 3/4, step 46/93, total step 232/372, training_loss = 0.1781\n",
      "epoch 3/4, step 47/93, total step 233/372, training_loss = 0.1728\n",
      "epoch 3/4, step 48/93, total step 234/372, training_loss = 0.1899\n",
      "epoch 3/4, step 49/93, total step 235/372, training_loss = 0.1567\n",
      "epoch 3/4, step 50/93, total step 236/372, training_loss = 0.1535\n",
      "epoch 3/4, step 51/93, total step 237/372, training_loss = 0.1678\n",
      "epoch 3/4, step 52/93, total step 238/372, training_loss = 0.1566\n",
      "epoch 3/4, step 53/93, total step 239/372, training_loss = 0.1630\n",
      "epoch 3/4, step 54/93, total step 240/372, training_loss = 0.1491\n",
      "epoch 3/4, step 55/93, total step 241/372, training_loss = 0.1557\n",
      "epoch 3/4, step 56/93, total step 242/372, training_loss = 0.1484\n",
      "epoch 3/4, step 57/93, total step 243/372, training_loss = 0.1522\n",
      "epoch 3/4, step 58/93, total step 244/372, training_loss = 0.1764\n",
      "epoch 3/4, step 59/93, total step 245/372, training_loss = 0.1411\n",
      "epoch 3/4, step 60/93, total step 246/372, training_loss = 0.1442\n",
      "epoch 3/4, step 61/93, total step 247/372, training_loss = 0.1476\n",
      "epoch 3/4, step 62/93, total step 248/372, training_loss = 0.1521\n",
      "epoch 3/4, step 63/93, total step 249/372, training_loss = 0.1733\n",
      "epoch 3/4, step 64/93, total step 250/372, training_loss = 0.1666\n",
      "epoch 3/4, step 65/93, total step 251/372, training_loss = 0.1606\n",
      "epoch 3/4, step 66/93, total step 252/372, training_loss = 0.1385\n",
      "epoch 3/4, step 67/93, total step 253/372, training_loss = 0.1515\n",
      "epoch 3/4, step 68/93, total step 254/372, training_loss = 0.1468\n",
      "epoch 3/4, step 69/93, total step 255/372, training_loss = 0.1490\n",
      "epoch 3/4, step 70/93, total step 256/372, training_loss = 0.1327\n",
      "epoch 3/4, step 71/93, total step 257/372, training_loss = 0.1246\n",
      "epoch 3/4, step 72/93, total step 258/372, training_loss = 0.1243\n",
      "epoch 3/4, step 73/93, total step 259/372, training_loss = 0.1383\n",
      "epoch 3/4, step 74/93, total step 260/372, training_loss = 0.1528\n",
      "epoch 3/4, step 75/93, total step 261/372, training_loss = 0.1264\n",
      "epoch 3/4, step 76/93, total step 262/372, training_loss = 0.1333\n",
      "epoch 3/4, step 77/93, total step 263/372, training_loss = 0.1359\n",
      "epoch 3/4, step 78/93, total step 264/372, training_loss = 0.1528\n",
      "epoch 3/4, step 79/93, total step 265/372, training_loss = 0.1430\n",
      "epoch 3/4, step 80/93, total step 266/372, training_loss = 0.1512\n",
      "epoch 3/4, step 81/93, total step 267/372, training_loss = 0.1480\n",
      "epoch 3/4, step 82/93, total step 268/372, training_loss = 0.1392\n",
      "epoch 3/4, step 83/93, total step 269/372, training_loss = 0.1551\n",
      "epoch 3/4, step 84/93, total step 270/372, training_loss = 0.1301\n",
      "epoch 3/4, step 85/93, total step 271/372, training_loss = 0.1423\n",
      "epoch 3/4, step 86/93, total step 272/372, training_loss = 0.1446\n",
      "epoch 3/4, step 87/93, total step 273/372, training_loss = 0.1180\n",
      "epoch 3/4, step 88/93, total step 274/372, training_loss = 0.1498\n",
      "epoch 3/4, step 89/93, total step 275/372, training_loss = 0.1430\n",
      "epoch 3/4, step 90/93, total step 276/372, training_loss = 0.1270\n",
      "epoch 3/4, step 91/93, total step 277/372, training_loss = 0.1354\n",
      "epoch 3/4, step 92/93, total step 278/372, training_loss = 0.1223\n",
      "epoch 3/4, step 93/93, total step 279/372, training_loss = 0.2710\n",
      "evaluation for epoch 3,  rocauc = 0.9995\n",
      "epoch 4/4, step 1/93, total step 280/372, training_loss = 0.1309\n",
      "epoch 4/4, step 2/93, total step 281/372, training_loss = 0.1382\n",
      "epoch 4/4, step 3/93, total step 282/372, training_loss = 0.1282\n",
      "epoch 4/4, step 4/93, total step 283/372, training_loss = 0.1256\n",
      "epoch 4/4, step 5/93, total step 284/372, training_loss = 0.1258\n",
      "epoch 4/4, step 6/93, total step 285/372, training_loss = 0.1339\n",
      "epoch 4/4, step 7/93, total step 286/372, training_loss = 0.1110\n",
      "epoch 4/4, step 8/93, total step 287/372, training_loss = 0.1418\n",
      "epoch 4/4, step 9/93, total step 288/372, training_loss = 0.1293\n",
      "epoch 4/4, step 10/93, total step 289/372, training_loss = 0.1264\n",
      "epoch 4/4, step 11/93, total step 290/372, training_loss = 0.1236\n",
      "epoch 4/4, step 12/93, total step 291/372, training_loss = 0.1190\n",
      "epoch 4/4, step 13/93, total step 292/372, training_loss = 0.1364\n",
      "epoch 4/4, step 14/93, total step 293/372, training_loss = 0.1427\n",
      "epoch 4/4, step 15/93, total step 294/372, training_loss = 0.0990\n",
      "epoch 4/4, step 16/93, total step 295/372, training_loss = 0.1163\n",
      "epoch 4/4, step 17/93, total step 296/372, training_loss = 0.1229\n",
      "epoch 4/4, step 18/93, total step 297/372, training_loss = 0.1205\n",
      "epoch 4/4, step 19/93, total step 298/372, training_loss = 0.0956\n",
      "epoch 4/4, step 20/93, total step 299/372, training_loss = 0.1029\n",
      "epoch 4/4, step 21/93, total step 300/372, training_loss = 0.1093\n",
      "epoch 4/4, step 22/93, total step 301/372, training_loss = 0.1290\n",
      "epoch 4/4, step 23/93, total step 302/372, training_loss = 0.1149\n",
      "epoch 4/4, step 24/93, total step 303/372, training_loss = 0.1302\n",
      "epoch 4/4, step 25/93, total step 304/372, training_loss = 0.1186\n",
      "epoch 4/4, step 26/93, total step 305/372, training_loss = 0.1116\n",
      "epoch 4/4, step 27/93, total step 306/372, training_loss = 0.1089\n",
      "epoch 4/4, step 28/93, total step 307/372, training_loss = 0.1114\n",
      "epoch 4/4, step 29/93, total step 308/372, training_loss = 0.0882\n",
      "epoch 4/4, step 30/93, total step 309/372, training_loss = 0.1091\n",
      "epoch 4/4, step 31/93, total step 310/372, training_loss = 0.1164\n",
      "epoch 4/4, step 32/93, total step 311/372, training_loss = 0.1129\n",
      "epoch 4/4, step 33/93, total step 312/372, training_loss = 0.1194\n",
      "epoch 4/4, step 34/93, total step 313/372, training_loss = 0.1321\n",
      "epoch 4/4, step 35/93, total step 314/372, training_loss = 0.1350\n",
      "epoch 4/4, step 36/93, total step 315/372, training_loss = 0.1192\n",
      "epoch 4/4, step 37/93, total step 316/372, training_loss = 0.1145\n",
      "epoch 4/4, step 38/93, total step 317/372, training_loss = 0.0972\n",
      "epoch 4/4, step 39/93, total step 318/372, training_loss = 0.1131\n",
      "epoch 4/4, step 40/93, total step 319/372, training_loss = 0.0924\n",
      "epoch 4/4, step 41/93, total step 320/372, training_loss = 0.1191\n",
      "epoch 4/4, step 42/93, total step 321/372, training_loss = 0.0952\n",
      "epoch 4/4, step 43/93, total step 322/372, training_loss = 0.1121\n",
      "epoch 4/4, step 44/93, total step 323/372, training_loss = 0.1016\n",
      "epoch 4/4, step 45/93, total step 324/372, training_loss = 0.1235\n",
      "epoch 4/4, step 46/93, total step 325/372, training_loss = 0.0913\n",
      "epoch 4/4, step 47/93, total step 326/372, training_loss = 0.1130\n",
      "epoch 4/4, step 48/93, total step 327/372, training_loss = 0.0977\n",
      "epoch 4/4, step 49/93, total step 328/372, training_loss = 0.1195\n",
      "epoch 4/4, step 50/93, total step 329/372, training_loss = 0.0940\n",
      "epoch 4/4, step 51/93, total step 330/372, training_loss = 0.1010\n",
      "epoch 4/4, step 52/93, total step 331/372, training_loss = 0.0943\n",
      "epoch 4/4, step 53/93, total step 332/372, training_loss = 0.0925\n",
      "epoch 4/4, step 54/93, total step 333/372, training_loss = 0.0855\n",
      "epoch 4/4, step 55/93, total step 334/372, training_loss = 0.0977\n",
      "epoch 4/4, step 56/93, total step 335/372, training_loss = 0.1031\n",
      "epoch 4/4, step 57/93, total step 336/372, training_loss = 0.1111\n",
      "epoch 4/4, step 58/93, total step 337/372, training_loss = 0.0903\n",
      "epoch 4/4, step 59/93, total step 338/372, training_loss = 0.1098\n",
      "epoch 4/4, step 60/93, total step 339/372, training_loss = 0.1297\n",
      "epoch 4/4, step 61/93, total step 340/372, training_loss = 0.1131\n",
      "epoch 4/4, step 62/93, total step 341/372, training_loss = 0.1110\n",
      "epoch 4/4, step 63/93, total step 342/372, training_loss = 0.1053\n",
      "epoch 4/4, step 64/93, total step 343/372, training_loss = 0.1112\n",
      "epoch 4/4, step 65/93, total step 344/372, training_loss = 0.0922\n",
      "epoch 4/4, step 66/93, total step 345/372, training_loss = 0.0935\n",
      "epoch 4/4, step 67/93, total step 346/372, training_loss = 0.0929\n",
      "epoch 4/4, step 68/93, total step 347/372, training_loss = 0.0827\n",
      "epoch 4/4, step 69/93, total step 348/372, training_loss = 0.0784\n",
      "epoch 4/4, step 70/93, total step 349/372, training_loss = 0.1062\n",
      "epoch 4/4, step 71/93, total step 350/372, training_loss = 0.0976\n",
      "epoch 4/4, step 72/93, total step 351/372, training_loss = 0.1023\n",
      "epoch 4/4, step 73/93, total step 352/372, training_loss = 0.0852\n",
      "epoch 4/4, step 74/93, total step 353/372, training_loss = 0.0973\n",
      "epoch 4/4, step 75/93, total step 354/372, training_loss = 0.0809\n",
      "epoch 4/4, step 76/93, total step 355/372, training_loss = 0.0916\n",
      "epoch 4/4, step 77/93, total step 356/372, training_loss = 0.0835\n",
      "epoch 4/4, step 78/93, total step 357/372, training_loss = 0.0727\n",
      "epoch 4/4, step 79/93, total step 358/372, training_loss = 0.0885\n",
      "epoch 4/4, step 80/93, total step 359/372, training_loss = 0.0816\n",
      "epoch 4/4, step 81/93, total step 360/372, training_loss = 0.0912\n",
      "epoch 4/4, step 82/93, total step 361/372, training_loss = 0.1094\n",
      "epoch 4/4, step 83/93, total step 362/372, training_loss = 0.0801\n",
      "epoch 4/4, step 84/93, total step 363/372, training_loss = 0.0972\n",
      "epoch 4/4, step 85/93, total step 364/372, training_loss = 0.0711\n",
      "epoch 4/4, step 86/93, total step 365/372, training_loss = 0.0870\n",
      "epoch 4/4, step 87/93, total step 366/372, training_loss = 0.0741\n",
      "epoch 4/4, step 88/93, total step 367/372, training_loss = 0.0828\n",
      "epoch 4/4, step 89/93, total step 368/372, training_loss = 0.0913\n",
      "epoch 4/4, step 90/93, total step 369/372, training_loss = 0.0857\n",
      "epoch 4/4, step 91/93, total step 370/372, training_loss = 0.0844\n",
      "epoch 4/4, step 92/93, total step 371/372, training_loss = 0.1276\n",
      "epoch 4/4, step 93/93, total step 372/372, training_loss = 0.1208\n",
      "evaluation for epoch 4,  rocauc = 0.9999\n",
      "CPU times: user 2min 2s, sys: 35.3 s, total: 2min 37s\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss and metric\n",
    "Once we're done training we want to visualize our Loss and Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "zY9GjuN7clDi",
    "outputId": "563dbd46-aa61-4ec9-e78b-286b9628b8ed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Val AUC\")\n",
    "x = [(i + 1) for i in range(len(metric_values))]\n",
    "y = metric_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model and understand the results\n",
    "### Evaluate the model on the test dataset\n",
    "\n",
    "After training and validation, we now have the best model as determined by the validation dataset. But now we need to evaluate the model on the test dataset to check whether the final model is robust and not over-fitting. We'll use these predictions to generate a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sVoATkhclG5",
    "outputId": "d22515fb-5b31-4893-a49f-34b5a5feaa88"
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = net(test_images).argmax(dim=1)\n",
    "        \n",
    "        for i in range(len(pred)):\n",
    "            y_true.append(test_labels[i].item())\n",
    "            y_pred.append(pred[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some light analytics - classification report\n",
    "\n",
    "We'll utilize scikit-learn's classification report to get the precision, recall, and f1-score for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIcAG1KPdK7T",
    "outputId": "9341ade1-cc56-4069-be54-66e53297e52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   AbdomenCT     0.9801    0.9840    0.9820      1000\n",
      "   BreastMRI     0.9944    0.9933    0.9939       895\n",
      "         CXR     0.9980    0.9840    0.9909      1000\n",
      "     ChestCT     0.9960    1.0000    0.9980      1000\n",
      "        Hand     0.9841    0.9890    0.9865      1000\n",
      "      HeadCT     0.9830    0.9850    0.9840      1000\n",
      "\n",
      "    accuracy                         0.9891      5895\n",
      "   macro avg     0.9893    0.9892    0.9892      5895\n",
      "weighted avg     0.9892    0.9891    0.9891      5895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some light analytics - confusion matrix\n",
    "\n",
    "Let's also create a confusion matrix to get a better understanding of the failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "e89fSZVSclKf",
    "outputId": "d85e4a68-9ed3-48c8-cfce-4a2e4bf5c2f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FixedFormatter should only be used together with FixedLocator\n",
      "FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cmat = confusion_matrix(y_true, y_pred)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion_matrix(y_true, y_pred), cmap=\"terrain\", interpolation='nearest')\n",
    "fig.colorbar(cax)\n",
    "\n",
    "ax.set_xticklabels(['']+class_names, rotation=270)\n",
    "ax.set_yticklabels(['']+class_names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caution !!!\n",
    "### please shutdown all kernels with [Kernel] menu >  [Shutdown All Kernel]  before launch next notebook\n",
    "\n",
    "## Navigation\n",
    "- [01_getting started](./01_getting.ipynb)\n",
    "\n",
    "- [02_pipeline_01](./02_pipeline_01.ipynb)\n",
    "- [02_pipeline_02](./02_pipeline_02.ipynb)\n",
    "- [02_pipeline_03](./02_pipeline_03.ipynb)\n",
    "- [02_pipeline_04](./02_pipeline_04.ipynb)\n",
    "\n",
    "- [03_brain_gan Next ](./03_brain_gan_01.ipynb)\n",
    "\n",
    "- [04_spleen_segment](./04_spleen_segment.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac baseline](./05_challenge_cardiac_baseline.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac workspace](./05_challenge_cardiac_workspace.ipynb) \n",
    "\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/monai.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Monai_bootcamp_01_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
